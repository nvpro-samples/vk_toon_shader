#version 460
#extension GL_NV_ray_tracing : require
#extension GL_GOOGLE_include_directive : enable

//-------------------------------------------------------------------------------------------------
// Default ray generation
// - Will sample the pixel n-number of time: samples
// - Will jitter the camera in sub-pixel to do anitaliasing
//-------------------------------------------------------------------------------------------------


#include "binding.glsl"
#include "share.glsl"

// clang-format off
layout(set = 0, binding = 0) uniform accelerationStructureNV topLevelAS;  // Scene BVH
layout(set = 0, binding = 1, rgba32f) uniform image2D image[];            // In/Out rendering images 0: color, 1: data

layout(set = 1, binding = B_SCENE) uniform _Scene {Scene sceneInfo;};
// clang-format on

//------------------------------------
// Push constant from the application
//------------------------------------
layout(push_constant) uniform Constants
{
  vec3  c_backgroundColor;
  int   c_frame;  // Current frame
  vec3  c_lightDir;
  float c_maxRayLenght;  // Trace depth
  int   c_samples;       // Number of samples per pixel
  int   c_nbSteps;
};

// Payload
layout(location = 0) rayPayloadNV PerRayData_raytrace prd;


//-------------------------------
// Ray generation
//-------------------------------
void main()
{
  vec4 hitValue      = vec4(0);
  vec4 bufferEncoded = vec4(0);  // xy: normal, z, object ID, w, depth

  for(int smpl = 0; smpl < c_samples; ++smpl)
  {
    // Initialize the random number
    uint  seed = tea(gl_LaunchIDNV.y * gl_LaunchSizeNV.x + gl_LaunchIDNV.x, c_frame * c_samples + smpl);
    float r1   = rnd(seed);
    float r2   = rnd(seed);

    bool first_frame = c_frame == 0 && smpl == 0;

    // Subpixel jitter: send the ray through a different position inside the pixel each time, to provide antialiasing.
    vec2 subpixel_jitter = first_frame ? vec2(0.5f, 0.5f) : vec2(r1, r2);

    const vec2 pixelCenter = vec2(gl_LaunchIDNV.xy) + subpixel_jitter;

    const vec2 inUV = pixelCenter / vec2(gl_LaunchSizeNV.xy);
    vec2       d    = inUV * 2.0 - 1.0;

    // Initialize ray information
    mat4  viewInverse = inverse(sceneInfo.modelView);
    mat4  projInverse = inverse(sceneInfo.projection);
    vec4  origin      = viewInverse * vec4(0, 0, 0, 1);
    vec4  target      = projInverse * vec4(d.x, d.y, 1, 1);
    vec4  direction   = viewInverse * vec4(normalize(target.xyz), 0);
    float Tmin        = 0.001;
    float Tmax        = 100000.0;

    // Payload
    prd.result     = vec4(0.f);
    prd.importance = vec3(1.f);
    prd.seed       = seed;
    prd.rayDepth   = 0;
    prd.roughness  = 0;
    prd.normal     = vec3(0.f);
    prd.depth      = -1;
    prd.objId      = 0;

    traceNV(topLevelAS,         // acceleration structure
            gl_RayFlagsNoneNV,  // rayFlags
            0xFF,               // cullMask
            0,                  // sbtRecordOffset
            0,                  // sbtRecordStride
            0,                  // missIndex
            origin.xyz,         // ray origin
            Tmin,               // ray min range
            direction.xyz,      // ray direction
            Tmax,               // ray max range
            0                   // payload layout(location = 0)
    );

    // Accumulating the result for this sample
    hitValue += prd.result;

    vec2 n        = encode(prd.normal);
    bufferEncoded = vec4(n, prd.depth, intBitsToFloat(prd.objId));
  }

  // Average result
  hitValue = hitValue / c_samples;

  // Do accumulation over time
  if(c_frame > 0)
  {
    float a         = 1.0f / float(c_frame);
    vec3  old_color = imageLoad(image[0], ivec2(gl_LaunchIDNV.xy)).xyz;
    imageStore(image[0], ivec2(gl_LaunchIDNV.xy), vec4(mix(old_color, hitValue.xyz, a), hitValue.a));
  }
  else
  {
    // First frame, replace value in the buffer
    imageStore(image[0], ivec2(gl_LaunchIDNV.xy), hitValue);
    imageStore(image[1], ivec2(gl_LaunchIDNV.xy), bufferEncoded);
  }
}
